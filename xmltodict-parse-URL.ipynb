{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use xmltodict to transfer XML into a dictionary, then read into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import xmltodict\n",
    "import csv\n",
    "import re\n",
    "from six.moves.urllib.parse import urlencode, urljoin\n",
    "from six.moves.html_parser import HTMLParser\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from a list of NCTID call the XML files from clinicalTrials.gov \n",
    "#get the list of NCTID\n",
    "def NCTID_input(xlsxfile):\n",
    "    \"\"\"\n",
    "    Get the input NCTID as a list\n",
    "    :param xlsxfile\n",
    "    :return the list\n",
    "    \"\"\"\n",
    "    NCTID_list = []\n",
    "    filepath = \"input\\\\\"+xlsxfile\n",
    "    df = pd.read_excel(filepath, sheet_name='Sheet1')\n",
    "    NCTID_list = df['NCT Number'].dropna().tolist()\n",
    "    return NCTID_list\n",
    "\n",
    "\n",
    "#call the xml from clinicalTrials.gov using request.get()\n",
    "BASE_URL = \"https://clinicaltrials.gov/ct2/show/\"\n",
    "\n",
    "def get_study(nct_id):\n",
    "    \"\"\"\n",
    "    Pull the XML for the study\n",
    "    :param nct_id:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    nct_id=nct_id.strip()\n",
    "    t = urljoin(BASE_URL, nct_id)\n",
    "    full_url = t + \"?\" + urlencode(dict(displayxml=True))\n",
    "    response = requests.get(full_url)\n",
    "    if not response.status_code == 200:\n",
    "        raise ValueError(\"Unable to load study {}\".format(nct_id))\n",
    "    return response.text\n",
    "\n",
    "# primary outcome info \n",
    "#  -- if more than 1, the primary outcome is a list of dictionaries \n",
    "#  -- if is 1, the primary outcome is a dictionary --> not yet tested\n",
    "def outcome(tag):\n",
    "    \"\"\"\n",
    "    Pull the outcomes information from XML file\n",
    "    :param tag_name\n",
    "    :return 1.counts of the tags, 2. subtag content (measure, timeframe,description) as a list \n",
    "    \"\"\"\n",
    "    outcome_list =[]\n",
    "    if type(content[tag]) is list:\n",
    "        for i in content[tag]:\n",
    "            #i = {key: value.replace('\\n','') for key, value in i.items()}\n",
    "            outcome_content = json.dumps(i) \n",
    "            outcome_list.append(outcome_content)\n",
    "        outcome_count = len(content[tag])\n",
    "    else:\n",
    "        for j in content[tag]:\n",
    "            outcome_list.append(j+\":\"+content[tag][j])\n",
    "            #outcome_list.append(j+\":\"+content[tag][j].replace('\\n',''))\n",
    "        outcome_count = 1\n",
    "    outcome_value = '|'.join(outcome_list)\n",
    "    return(outcome_count,outcome_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please give the file name contains NCTID list:CT69.xlsx\n",
      "please give the file name for output: CT69_xmltodict_out_010303.csv\n",
      "69 files need to be processed.\n",
      "NCT02599389 processed!\n",
      "NCT02710656 processed!\n",
      "NCT01221610 processed!\n",
      "NCT01867736 processed!\n",
      "NCT00696956 processed!\n",
      "NCT00930813 processed!\n",
      "NCT01594684 processed!\n",
      "NCT02498080 processed!\n",
      "NCT01558505 processed!\n",
      "NCT03175744 processed!\n",
      "NCT02963649 processed!\n",
      "NCT01816412 processed!\n",
      "NCT02063672 processed!\n",
      "NCT01566461 processed!\n",
      "NCT01947478 processed!\n",
      "NCT01412541 processed!\n",
      "NCT00987324 processed!\n",
      "NCT01495533 processed!\n",
      "NCT01239953 processed!\n",
      "NCT01239940 processed!\n",
      "NCT01255956 processed!\n",
      "NCT00485030 processed!\n",
      "NCT01093300 processed!\n",
      "NCT02924857 processed!\n",
      "NCT02561299 processed!\n",
      "NCT01858428 processed!\n",
      "NCT00472472 processed!\n",
      "NCT02965677 processed!\n",
      "NCT01247402 processed!\n",
      "NCT03884257 processed!\n",
      "NCT02129634 processed!\n",
      "NCT02772224 processed!\n",
      "NCT01556542 processed!\n",
      "NCT02033135 processed!\n",
      "NCT02812966 processed!\n",
      "NCT00776906 processed!\n",
      "NCT02923193 processed!\n",
      "NCT02936622 processed!\n",
      "NCT01175850 processed!\n",
      "NCT02625740 processed!\n",
      "NCT01858363 processed!\n",
      "NCT01366482 processed!\n",
      "NCT02004951 processed!\n",
      "NCT02962141 processed!\n",
      "NCT03241459 processed!\n",
      "NCT02962232 processed!\n",
      "NCT02701543 processed!\n",
      "NCT03421561 processed!\n",
      "NCT01728441 processed!\n",
      "NCT01960647 processed!\n",
      "NCT01969630 processed!\n",
      "NCT02279784 processed!\n",
      "NCT02517827 processed!\n",
      "NCT03064126 processed!\n",
      "NCT02013193 processed!\n",
      "NCT02145065 processed!\n",
      "NCT01305070 processed!\n",
      "NCT00471289 processed!\n",
      "NCT01083394 processed!\n",
      "NCT03206762 processed!\n",
      "NCT01952457 processed!\n",
      "NCT00986752 processed!\n",
      "NCT01298947 processed!\n",
      "NCT03625830 processed!\n",
      "NCT02891005 processed!\n",
      "NCT00766129 processed!\n",
      "NCT03149913 processed!\n",
      "NCT03332264 processed!\n",
      "NCT01970579 processed!\n",
      "69 files processed and wrote into the outputfile.\n"
     ]
    }
   ],
   "source": [
    "NCTIDfile = input('please give the file name contains NCTID list:' )\n",
    "outfilename = input('please give the file name for output: ')\n",
    "\n",
    "outputfile = \"output\\\\\"+outfilename\n",
    "\n",
    "NCTID_list = NCTID_input(NCTIDfile)\n",
    "print (str(len(NCTID_list))+' files need to be processed.')\n",
    "\n",
    "content_dict = {}\n",
    "\n",
    "k = 0\n",
    "for i in NCTID_list:\n",
    "    xml_str= get_study(i)\n",
    "    #the get_study function returns xml in string. need to read the tree from a string.\n",
    "    tree = ET.ElementTree(ET.fromstring(xml_str))\n",
    "    root = tree.getroot()\n",
    "    xmlstr = ET.tostring(root, encoding='utf8', method='xml')\n",
    "    xmlstr = xmlstr.replace(b'<?xml version=\\'1.0\\' encoding=\\'utf8\\'?>\\n', b'') \n",
    "    xmlstr = xmlstr.replace(b'\\n',b'')\n",
    "    data_dict = xmltodict.parse(xmlstr)\n",
    "    \n",
    "    #only one key in data_dict --> clinical study\n",
    "    for key in data_dict:\n",
    "        content=data_dict[key]\n",
    "    \n",
    "    # getting nct_id\n",
    "    content_dict['NCTID'] = content['id_info']['nct_id']\n",
    "    #title\n",
    "    content_dict['Title'] = content['brief_title']\n",
    "    # acronym\n",
    "    if 'acronym' in content:\n",
    "        content_dict['Acronym'] = content['acronym']\n",
    "    else:\n",
    "        content_dict['Acronym'] = \"None\"\n",
    "    # status\n",
    "    content_dict['Status'] = content['overall_status']\n",
    "    #oversight_info\n",
    "    if 'oversight_info' in content:\n",
    "        if 'has_dmc' in content['oversight_info']:\n",
    "            content_dict['dmc_info'] = content['oversight_info']['has_dmc']\n",
    "        else:\n",
    "            content_dict['dmc_info'] = \"None\"\n",
    "    else:\n",
    "        content_dict['dmc_info'] = \"None\"\n",
    "    # results: if tag 'clinical_results' available, then has_results\n",
    "    if 'clinical_results' in content:\n",
    "        content_dict['Study Results'] = \"has results\"\n",
    "    else:\n",
    "        content_dict['Study Results'] = \"no results\"\n",
    "    # condition - multiple\n",
    "    content_dict['Condition'] = content['condition']\n",
    "    # intervention - multiple dictionary - as list\n",
    "    intervention_list = []\n",
    "    if type(content['intervention']) is list:\n",
    "        for j in content['intervention']:\n",
    "            intervention = j['intervention_type']+\":\"+j['intervention_name']\n",
    "            intervention_list.append(intervention)\n",
    "        content_dict['Intervention'] = '|'.join(intervention_list)\n",
    "    else:\n",
    "        content_dict['Intervention'] = content['intervention']['intervention_type']+\":\"+content['intervention']['intervention_name']\n",
    "    #lead_sponsor\n",
    "    content_dict['Sponsor'] = content['sponsors']['lead_sponsor']['agency']\n",
    "    #lead_sponsor_type maybe equal to \"Funded Bys\"\n",
    "    content_dict['Funded Bys'] = content['sponsors']['lead_sponsor']['agency_class']\n",
    "    #gender under eligibility one tag\n",
    "    content_dict['Gender'] = content['eligibility']['gender']\n",
    "    #age\n",
    "    if content['eligibility']['maximum_age'] != \"N/A\": \n",
    "        max_age = content['eligibility']['maximum_age'] \n",
    "    else:\n",
    "        max_age =\"\"\n",
    "    content_dict['Age'] = content['eligibility']['minimum_age']+\"-\"+max_age\n",
    "    #phase\n",
    "    if 'phase' in content: \n",
    "        content_dict['Phase'] = content['phase']\n",
    "    else:\n",
    "        content_dict['Phase'] = \"None\"\n",
    "    #study type\n",
    "    content_dict['Study Type'] = content['study_type']\n",
    "    #enrollment number\n",
    "    if type(content['enrollment']) is collections.OrderedDict:\n",
    "        content_dict['Enrollment'] = content['enrollment']['#text']\n",
    "    else:\n",
    "        content_dict['Enrollment'] = content['enrollment']\n",
    "    #location\n",
    "    if 'location' in content: \n",
    "        if type(content['location']) is list:\n",
    "            content_dict['Sites number'] = len(content['location'])\n",
    "        else:\n",
    "            content_dict['Sites number'] = 1\n",
    "    else:\n",
    "        content_dict['Sites number'] = \"None\"\n",
    "    #study_design_info\n",
    "    study_design_info = []\n",
    "    for j in content['study_design_info']:\n",
    "        study_design = j+\":\"+content['study_design_info'][j]\n",
    "        study_design_info.append(study_design)\n",
    "    content_dict['Study Design Info'] = '|'.join(study_design_info)\n",
    "    #primary outcome\n",
    "    primary_outcome = outcome('primary_outcome')\n",
    "    content_dict['Primary Outcome Count'] = primary_outcome[0]\n",
    "    content_dict['Primary Outcome'] = primary_outcome[1]\n",
    "    #secondary outcome\n",
    "    if 'secondary_outcome' in content:\n",
    "        secondary_outcome = outcome('secondary_outcome')\n",
    "        content_dict['Secondary Outcome Count'] = secondary_outcome[0]\n",
    "        content_dict['Secondary Outcome'] = secondary_outcome[1]\n",
    "    else:\n",
    "        content_dict['Secondary Outcome Count'] = 0\n",
    "        content_dict['Secondary Outcome'] = \"None\"\n",
    "    #arm\n",
    "    if 'arm_group' in content:\n",
    "        arm_group = outcome('arm_group')\n",
    "        content_dict['arm group count'] = arm_group[0]\n",
    "        content_dict['arm group list'] = arm_group[1]\n",
    "    else:\n",
    "        content_dict['arm group count'] = 0\n",
    "        content_dict['arm group list'] = \"None\"\n",
    "    #inclusion_exclusion_criteria\n",
    "    if 'criteria' in content['eligibility']:\n",
    "        inclusion_exclusion = content['eligibility']['criteria']['textblock']\n",
    "        inclusion_exclusion = str(inclusion_exclusion)\n",
    "        inclusion_exclusion = inclusion_exclusion.replace('\\n','')\n",
    "        inclusion_exclusion = re.sub(' +', ' ', inclusion_exclusion) \n",
    "        content_dict['inclusion_exclusion'] = inclusion_exclusion\n",
    "    else:\n",
    "        content_dict['inclusion_exclusion'] = \"None\"\n",
    "    #mesh term\n",
    "    if 'intervention_browse' in content:\n",
    "        if 'mesh_term' in content['intervention_browse']:\n",
    "            content_dict['mesh_term'] = content['intervention_browse']['mesh_term']\n",
    "    else:\n",
    "        content_dict['mesh_term'] = \"None\"\n",
    "    #keyword\n",
    "    if 'keyword' in content:\n",
    "        content_dict['keyword'] = content['keyword']\n",
    "    else:\n",
    "        content_dict['keyword'] = \"None\"\n",
    "    print (i+ ' processed!')\n",
    "    # input the dictionary into a csv file\n",
    "    with open(outputfile, 'a', encoding = 'utf8') as f:\n",
    "        for key in content_dict.keys():\n",
    "            f.write(\"%s:%s||\"%(key,content_dict[key]))\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n",
    "    #dump the dictionary into json file\n",
    "    jfilename = \"output\\\\json\\\\\"+i+\"_data.json\"\n",
    "    with open(jfilename, 'w') as fj:\n",
    "        json.dump(content_dict, fj,indent=4)\n",
    "    fj.close()\n",
    "    k=k+1\n",
    "\n",
    "print(str(k)+ ' files processed and wrote into the outputfile.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
